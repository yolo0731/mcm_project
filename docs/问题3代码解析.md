# 问题3: 高速列车轴承智能故障诊断 - 代码解析文档

## 项目概述

本项目实现了基于域适应（Domain Adaptation）技术的高速列车轴承智能故障诊断系统，主要解决从实验室台架数据（源域）迁移到实际列车运营数据（目标域）的故障分类问题。整个系统采用DANN（Domain-Adversarial Neural Network）架构，通过两阶段训练策略实现跨域故障诊断。

### 核心技术架构
- **源域数据**: 161个轴承试验台架振动数据文件（有标签）
- **目标域数据**: 16个实际列车轴承故障文件（无标签）
- **故障类型**: 4类（正常N、滚珠故障B、内圈故障IR、外圈故障OR）
- **核心算法**: DANN域对抗神经网络
- **特征提取**: 多尺度1D CNN + 注意力机制
- **数据处理**: 滑窗分割、归一化、类别平衡采样

## 文件结构与功能详解

### 1. 核心模块文件

#### `paths.py` - 路径管理模块
**功能**: 项目路径配置和目录管理
```python
ROOT: Path = Path(__file__).resolve().parent.parent.parent
DEFAULT_PROCESSED_DIR: Path = ROOT / "data" / "processed" / "问题3"
DEFAULT_FIGS_DIR: Path = ROOT / "figs" / "问题3"
```

**核心函数**:
- `ensure_output_dirs()`: 确保输出目录存在，自动创建所需文件夹

#### `data.py` - 数据处理核心模块
**功能**: 完整的数据加载、预处理和Dataset实现

**关键常量**:
```python
LABEL_TO_INDEX: Dict[str, int] = {"N": 0, "B": 1, "IR": 2, "OR": 3, "Unknown": -1}
WINDOW_SIZE: int = 2048  # 滑窗大小
STEP_SIZE: int = 768     # 滑窗步长（62.5%重叠）
```

**核心类**:
1. **`SampleItem`**: 数据样本元信息容器
   - 存储文件路径、滑窗位置、标签、域标识等

2. **`BearingDataset`**: PyTorch Dataset实现
   - **滑窗分割**: 将长时间序列按固定窗口分割
   - **数据增强**: 通过重叠滑窗增加样本量
   - **类别平衡**: 针对不同故障类型采用不同采样策略
   - **缓存机制**: 避免重复加载.mat文件
   - **预处理流程**:
     ```python
     signal = detrend(signal, type="linear")  # 去趋势
     if normalize:
         signal = (signal - np.mean(signal)) / std  # 标准化
     ```

**数据处理策略**:
- **类别平衡采样**:
  - N类: 最多200个窗口/文件
  - B类: 最多180个窗口/文件（保护少数类）
  - IR类: 最多120个窗口/文件
  - OR类: 最多100个窗口/文件

**核心函数**:
- `stratified_train_val_split()`: 分层训练/验证集划分
- `create_dataloaders()`: 创建训练、验证、目标域数据加载器
- `compute_class_weights()`: 计算类别权重用于损失函数
- `make_balanced_sampler()`: 创建平衡采样器

### 2. 模型架构文件

#### `models.py` - 神经网络模型定义
**功能**: 实现DANN架构的所有组件

**核心组件**:

1. **`GradientReversalFn`**: 梯度反转层实现
   ```python
   @staticmethod
   def backward(ctx, grad_output: Tensor) -> tuple[Tensor, None]:
       return grad_output.neg() * ctx.alpha, None
   ```
   - **原理**: 前向传播不变，反向传播梯度乘以-α
   - **作用**: 实现对抗训练，让特征提取器"欺骗"域分类器

2. **`FeatureExtractor`**: 多尺度特征提取器
   - **架构**: 1D CNN + 多分支 + 注意力池化
   - **设计理念**:
     ```python
     # 主干网络
     self.stem = nn.Sequential(
         nn.Conv1d(1, 32, kernel_size=32, stride=8, padding=16),
         nn.BatchNorm1d(32),
         nn.ReLU(inplace=True),
         nn.MaxPool1d(kernel_size=4, stride=2),
     )

     # 多尺度分支
     kernel_sizes = (7, 15, 31)  # 捕获不同频率特征
     self.branches = nn.ModuleList([...])

     # 注意力机制
     self.attention = nn.Sequential(
         nn.Linear(branch_channels, att_hidden),
         nn.ReLU(inplace=True),
         nn.Linear(att_hidden, 1),
     )
     ```
   - **输出**: 128维特征向量

3. **`LabelClassifier`**: 故障分类器
   - **架构**: 残差MLP + LayerNorm + BatchNorm
   - **特殊设计**:
     - 减少dropout保护B类信息
     - 添加BatchNorm提升类别分离度
     - 单样本时跳过BatchNorm避免错误

4. **`DomainClassifier`**: 域判别器
   - **架构**: GRL + 简单MLP
   - **功能**: 区分源域(0)和目标域(1)数据
   - **对抗机制**: 通过GRL实现最小-最大博弈

5. **`DANNModel`**: 完整DANN模型
   - **输入**: 振动信号 (batch_size, 1, 2048)
   - **输出**: (标签logits, 域logits, 特征向量)
   - **前向传播**:
     ```python
     def forward(self, x: Tensor, alpha: float = 1.0):
         features = self.feature_extractor(x)
         label_logits = self.label_classifier(features)
         domain_logits = self.domain_classifier(features, alpha=alpha)
         return label_logits, domain_logits, features
     ```

### 3. 训练模块文件

#### `train_utils.py` - 训练工具函数
**功能**: 提供训练过程中的通用工具函数

**核心函数**:
1. **`set_seed()`**: 设置随机种子确保可复现性
2. **`train_source_epoch()`**: 源域训练一个epoch
   - 标准监督学习训练
   - 梯度裁剪防止梯度爆炸
3. **`train_dann_epoch()`**: DANN训练一个epoch
   - 同时处理源域和目标域数据
   - 实现对抗损失计算
   - α参数动态调整
4. **`evaluate_source()/evaluate_dann()`**: 模型评估函数

#### `train_source.py` - 源域预训练
**功能**: 第一阶段训练，在源域数据上训练分类器

**训练流程**:
1. **数据准备**: 加载源域数据，分层划分训练/验证集
2. **模型初始化**: 创建SourceClassifier（特征提取器+分类器）
3. **损失函数**: 带类别权重的交叉熵损失
4. **优化器**: Adam + 余弦退火学习率调度
5. **训练循环**:
   ```python
   for epoch in range(1, args.epochs + 1):
       train_stats = train_source_epoch(model, train_loader, criterion, optimizer, device)
       val_stats = evaluate_source(model, val_loader, criterion, device)
       # 保存最佳模型
       if val_stats.accuracy > best_val_acc:
           torch.save(checkpoint, best_path)
   ```

**输出文件**:
- `source_pretrained_model.pth`: 预训练模型权重
- `source_training_history.json`: 训练历史记录

#### `train_dann.py` - DANN域适应训练
**功能**: 第二阶段训练，实现域适应

**核心算法原理**:
DANN采用对抗训练策略，目标函数为:
```
L_total = L_class - λL_domain
```
其中：
- L_class: 源域分类损失
- L_domain: 域判别损失
- λ: 对抗权重（α参数）

**训练流程**:
1. **模型初始化**: 创建DANNModel，加载预训练权重
2. **优化器配置**:
   ```python
   optimizer = torch.optim.Adam([
       {"params": model.feature_extractor.parameters(), "lr": args.lr},
       {"params": model.label_classifier.parameters(), "lr": args.lr},
       {"params": model.domain_classifier.parameters(), "lr": lr_domain},
   ])
   ```
3. **α参数调度**:
   ```python
   # 逐渐增加对抗权重
   progress = current_step / total_steps
   alpha = alpha_max * (2.0 / (1.0 + math.exp(-10.0 * progress)) - 1.0)
   ```

**对抗训练机制**:
- **特征提取器**: 既要保持分类性能，又要让域分类器无法区分域
- **域分类器**: 努力区分源域和目标域特征
- **梯度反转层**: 让特征提取器梯度反向，实现对抗

### 4. 推理与分析模块

#### `inference.py` - 目标域推理
**功能**: 使用训练好的DANN模型对目标域数据进行故障诊断

**推理策略**:
1. **滑窗预测**: 对每个文件的所有滑窗进行预测
2. **置信度聚合**:
   ```python
   # Top-k窗口选择
   if top_ratio < 1.0:
       k = max(1, int(round(stacked_logits.shape[0] * top_ratio)))
       top_idx = np.argsort(window_conf)[-k:]
       selected_logits = stacked_logits[top_idx]

   # 温度缩放 + 平均
   mean_logits = selected_logits.mean(axis=0) / temperature
   mean_probs = softmax(mean_logits)
   ```

3. **可靠性评估**:
   ```python
   # 综合可靠性指标
   reliability = 0.6 * confidence + 0.3 * pred_consistency + 0.1 * (1 - uncertainty/np.log(4))
   reliable_prediction = confidence >= 0.7 and reliability >= 0.6
   ```

**输出结果**:
- 预测标签和置信度
- 不确定性量化
- 可靠性评估
- 每个样本的概率分布

#### `tsne_analysis.py` - t-SNE可视化分析
**功能**: 通过t-SNE降维可视化特征分布，分析域适应效果

**可视化内容**:
- 源域和目标域特征分布
- 不同故障类型的聚类情况
- 域适应前后的特征对齐程度

#### `visualization.py` - 可视化工具
**功能**: 提供各种绘图函数
- 训练曲线绘制
- 预测分布统计
- 结果表格生成

### 5. 集成运行模块

#### `run_all.py` - 端到端执行器
**功能**: 整合所有步骤，实现一键运行完整流程

**执行流程**:
```python
def run_pipeline(args):
    # 第一阶段：源域预训练
    source_path = train_source.run_training(source_args)

    # 第二阶段：DANN域适应
    dann_path = train_dann.run_training(dann_args)

    # 第三阶段：目标域推理
    if not args.skip_inference:
        inference.run_inference(infer_args)

    # 第四阶段：特征可视化
    if not args.skip_tsne:
        tsne_analysis.plot_tsne(...)
```

## 算法原理深入解析

### 1. DANN域适应理论基础

**核心思想**: 通过对抗训练学习域不变特征表示

**数学表述**:
给定源域数据 $D_s = \{(x_i^s, y_i^s)\}$ 和目标域数据 $D_t = \{x_j^t\}$，DANN的目标是学习特征提取器 $G_f$，使得：

1. **分类性能**: $\min_{G_f, G_y} \mathcal{L}_{cls}(G_y(G_f(x^s)), y^s)$
2. **域混淆**: $\max_{G_f} \min_{G_d} \mathcal{L}_{domain}(G_d(G_f(x)), d)$

其中 $G_y$ 是标签分类器，$G_d$ 是域分类器。

**梯度反转层机制**:
$$\frac{\partial \mathcal{L}_{total}}{\partial \theta_f} = \frac{\partial \mathcal{L}_{cls}}{\partial \theta_f} - \lambda \frac{\partial \mathcal{L}_{domain}}{\partial \theta_f}$$

### 2. 轴承故障诊断的信号处理理论

**故障特征频率**:
- **外圈故障**: $f_{BPFO} = \frac{n}{2} f_r (1 - \frac{d}{D})$
- **内圈故障**: $f_{BPFI} = \frac{n}{2} f_r (1 + \frac{d}{D})$
- **滚动体故障**: $f_{BSF} = \frac{f_r D}{d} [1 - (\frac{d}{D})^2]$

其中：$f_r$=转频，$n$=滚动体数，$d$=滚动体直径，$D$=节径

**时域特征**:
- 正常状态：随机振动
- 故障状态：周期性冲击 + 调制信号

### 3. 深度学习模型设计理念

**多尺度特征提取**:
不同尺度的卷积核捕获不同频段的故障特征：
- 小核(7): 高频冲击特征
- 中核(15): 中频调制特征
- 大核(31): 低频包络特征

**注意力机制**:
自适应融合多尺度特征，提升关键特征的权重。

## 数据流程详解

### 1. 数据预处理流程

```
原始.mat文件 → loadmat() → 信号提取 → 去趋势 → 标准化 → 滑窗分割 → Dataset
```

**详细步骤**:
1. **文件解析**: 自动识别.mat文件中的振动信号变量
2. **信号清洗**: 线性去趋势去除基线漂移
3. **归一化**: Z-score标准化，均值0方差1
4. **滑窗分割**:
   - 窗口大小：2048点（约0.064秒@32kHz）
   - 步长：768点（62.5%重叠）
   - 确保充足的样本数量

### 2. 训练数据流

**源域训练阶段**:
```
源域数据 → 分层划分 → 平衡采样 → 批处理 → 特征提取 → 分类预测 → 损失计算 → 反向传播
```

**DANN训练阶段**:
```
源域数据 ────┐
             ├→ 特征提取 ─┬→ 标签分类 → 分类损失
目标域数据 ──┘           └→ 域分类 → 域损失(GRL) → 总损失 → 反向传播
```

### 3. 推理数据流

```
目标域文件 → 滑窗分割 → 批处理 → DANN推理 → Top-k选择 → 概率聚合 → 置信度评估 → 最终预测
```

## 模型性能与评估

### 1. 评估指标

**分类指标**:
- 准确率（Accuracy）
- 每类精确率/召回率
- 混淆矩阵分析

**可靠性指标**:
- 预测置信度
- 不确定性量化（熵）
- 一致性评估

**域适应指标**:
- 源域性能保持
- 目标域分类效果
- 特征对齐程度（t-SNE可视化）

### 2. 性能优化策略

**数据层面**:
- 类别平衡采样解决数据不平衡
- 滑窗重叠增加样本多样性
- 数据增强提升泛化能力

**模型层面**:
- 多尺度特征融合
- 注意力机制突出重要特征
- 残差连接防止梯度消失
- 适当的dropout防止过拟合

**训练层面**:
- 两阶段训练策略
- 动态α参数调整
- 梯度裁剪稳定训练
- 余弦退火学习率调度

## 可解释性分析

### 1. 事前可解释性

**模型结构透明性**:
- 明确的两阶段训练流程
- 可解释的多尺度CNN架构
- 清晰的对抗训练机制

**特征工程合理性**:
- 基于轴承故障机理的滑窗设计
- 符合信号处理理论的预处理步骤
- 多尺度卷积核对应不同故障特征频率

### 2. 迁移过程可解释性

**域适应机制**:
- GRL实现特征域混淆的数学原理明确
- α参数调度策略有理论支撑
- t-SNE可视化直观展示特征对齐过程

**知识迁移路径**:
- 第一阶段：学习通用故障特征表示
- 第二阶段：适应目标域数据分布
- 特征复用：底层特征通用，高层特征适应

### 3. 事后可解释性

**决策可信度评估**:
- 多层次置信度计算
- 基于熵的不确定性量化
- 窗口一致性分析

**预测结果分析**:
- 详细的概率分布输出
- 可靠性阈值判断
- 失败案例分析机制

## 工程实现亮点

### 1. 代码架构设计

**模块化设计**: 每个py文件职责明确，耦合度低
**配置管理**: 统一的参数管理和路径配置
**错误处理**: 完善的异常处理和边界情况考虑
**可扩展性**: 易于添加新的模型或数据处理方法

### 2. 性能优化

**内存优化**:
- 信号缓存机制避免重复加载
- 批处理提高GPU利用率
- 适当的数据采样减少内存占用

**计算优化**:
- PyTorch原生操作提高运算效率
- 梯度累积支持大批量训练
- 混合精度训练（可选）

### 3. 实用性考虑

**参数调优**:
- 丰富的命令行参数支持
- 网格搜索友好的接口设计
- 自动化的最优模型保存

**结果输出**:
- 标准化的CSV格式输出
- 高质量的可视化图表
- 详细的训练日志记录

## 使用指南

### 1. 环境配置
```bash
pip install torch torchvision torchaudio
pip install numpy pandas scikit-learn matplotlib seaborn
pip install scipy
```

### 2. 数据准备
- 源域数据：`data/processed/94feature.csv`
- 目标域数据：`data/processed/16feature.csv`
- CSV格式：包含file列指向.mat文件路径

### 3. 运行方式

**完整流程**:
```bash
python src/问题3/run_all.py --epochs-src 15 --epochs-dann 20
```

**分步运行**:
```bash
# 源域预训练
python src/问题3/train_source.py --epochs 15

# DANN适应
python src/问题3/train_dann.py --epochs 20

# 推理分析
python src/问题3/inference.py
```

### 4. 参数调优建议

**关键超参数**:
- `--epochs-src`: 源域训练轮数（建议10-20）
- `--epochs-dann`: DANN训练轮数（建议15-30）
- `--lr-src`: 源域学习率（建议1e-3）
- `--lr-dann`: DANN学习率（建议5e-4）
- `--alpha-max`: 最大对抗权重（建议0.5-2.0）

**调优策略**:
1. 先确保源域性能达标
2. 逐步增加DANN训练轮数
3. 调整学习率平衡训练稳定性
4. 通过t-SNE观察特征对齐效果

## 总结

本项目成功实现了一套完整的跨域轴承故障诊断系统，具有以下特色：

1. **理论扎实**: 基于DANN域适应理论和轴承故障机理
2. **实现完整**: 从数据处理到模型训练再到结果分析的全流程
3. **性能优秀**: 多项优化策略确保诊断准确性
4. **可解释强**: 从多个维度提供模型可解释性
5. **工程化程度高**: 模块化设计，易于部署和维护

该系统为工业故障诊断中的域适应问题提供了一个可行的解决方案，具有较强的实用价值和参考意义。