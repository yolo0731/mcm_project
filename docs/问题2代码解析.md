# 问题2：源域故障诊断 - 代码解析报告

## 概述

问题2是高速列车轴承智能故障诊断的源域数据分析，主要目标是构建可靠的故障分类模型。整个解决方案采用了先进的数据增强技术和多模型集成策略，通过滑动窗口和高斯噪声增强训练数据，提升模型在小样本场景下的性能。

## 整体架构与流程

### 主要文件结构
```
src/问题2/
├── 2.py                    # 主程序入口
├── problem2_config.py      # 配置文件
├── utils.py               # 工具函数
├── data_processing.py     # 数据预处理模块
├── feature_analysis.py    # 特征分析模块
├── augmentation.py        # 数据增强模块
├── modeling.py           # 建模训练模块
└── reporting.py          # 结果输出与可视化模块
```

## 详细代码解析

### 1. 主程序入口：2.py

**文件作用**: 整个问题2的核心调度程序，按照机器学习管道流程执行各个模块。

**核心流程**:
1. **环境初始化**: 设置matplotlib样式，配置字体和颜色主题
2. **数据加载**: 调用`load_feature_data()`加载94维特征数据
3. **数据预处理**: 通过`preprocess_features()`清洗和编码数据
4. **特征分析**: 使用`perform_feature_analysis()`筛选重要特征
5. **数据增强**: 通过`split_and_augment()`实施滑动窗口增强
6. **模型训练**: 调用`train_models()`训练多个分类器
7. **结果分析**: 生成性能报告、混淆矩阵和综合分析图表

**关键代码逻辑**:
```python
# 核心管道流程
df = load_feature_data(config)                    # 加载数据
target_col = infer_target_column(df, config)      # 推断目标列
data_bundle = preprocess_features(df, target_col, config)  # 预处理
feature_artifacts = perform_feature_analysis(data_bundle, config)  # 特征选择
augmentation_data = split_and_augment(...)        # 数据增强
model_artifacts = train_models(...)               # 模型训练
```

### 2. 配置管理：problem2_config.py

**文件作用**: 集中管理所有超参数和路径配置，支持灵活的实验配置。

**核心配置项**:
- **数据路径**: 支持多个候选路径自动检测
- **特征选择参数**: 方差阈值、特征数量范围
- **数据增强参数**: 窗口大小(70%)、步长(30%)、噪声水平(2%)
- **输出路径**: 图片和数据文件的保存位置

**设计特点**:
```python
@dataclass
class PipelineConfig:
    augmentation_window: float = 0.7      # 滑动窗口大小
    augmentation_stride: float = 0.3      # 滑动步长
    augmentation_noise: float = 0.02      # 高斯噪声水平
    max_top_features: int = 30            # 最大特征数
```

### 3. 工具函数：utils.py

**文件作用**: 提供文件I/O、图形显示和通用功能支持。

**核心功能**:
- `ensure_directory()`: 自动创建目录结构
- `save_figure()`: 标准化图片保存，设置DPI和格式
- `safe_display()`: 兼容Jupyter和CLI的显示函数
- `print_class_distribution()`: 格式化输出类别分布

### 4. 数据预处理：data_processing.py

**文件作用**: 负责原始数据的加载、清洗、编码和基础统计分析。

**DataBundle数据结构**:
```python
@dataclass
class DataBundle:
    df: pd.DataFrame           # 原始数据框
    target_col: str           # 目标列名
    feature_columns: List[str] # 特征列列表
    X: pd.DataFrame           # 特征矩阵
    y: pd.Series             # 标签序列
    X_numeric: pd.DataFrame   # 数值型特征
    numeric_columns: List[str] # 数值列名
    y_encoded: np.ndarray     # 编码后标签
    label_encoder: LabelEncoder # 标签编码器
    class_names: List[str]    # 类别名称
```

**核心处理流程**:
1. **数据加载**: 从CSV文件读取94维特征数据
2. **目标列推断**: 自动识别`label_cls`或`fault_type_orig`作为目标
3. **特征过滤**: 排除元数据列，保留纯特征列
4. **数据清洗**:
   - 处理缺失值（中位数填充）
   - 处理无穷值（替换为中位数）
   - 数据类型转换
5. **标签编码**: 使用LabelEncoder将字符串标签转为数值

**关键算法**:
```python
def preprocess_features(df, target_col, config):
    # 特征列筛选
    feature_columns = [col for col in df.columns if col not in config.meta_columns]

    # 缺失值处理
    if missing_count > 0:
        X_numeric = X_numeric.fillna(X_numeric.median())

    # 无穷值处理
    if inf_count > 0:
        X_numeric = X_numeric.replace([np.inf, -np.inf], np.nan).fillna(X_numeric.median())
```

### 5. 特征分析：feature_analysis.py

**文件作用**: 实施多方法特征重要性评估和特征选择，减少维度诅咒。

**FeatureArtifacts数据结构**:
```python
@dataclass
class FeatureArtifacts:
    feature_importance_df: pd.DataFrame  # 特征重要性表
    top_features: List[str]             # 选中的特征列表
    X_selected: pd.DataFrame            # 选中的特征数据
```

**多方法特征选择策略**:
1. **方差阈值过滤**: 移除低方差特征（阈值1e-6）
2. **单变量统计**: F-检验评估特征与目标的相关性
3. **随机森林重要性**: 基于信息增益的特征重要性
4. **梯度提升重要性**: 基于梯度的特征重要性

**综合评分算法**:
```python
# 特征重要性综合评分
feature_importance_df["combined_score"] = (
    0.3 * feature_importance_df["univariate_score"] +    # 单变量统计30%
    0.4 * feature_importance_df["rf_importance"] +       # 随机森林40%
    0.3 * feature_importance_df["gb_importance"]         # 梯度提升30%
)
```

**自适应特征数量选择**:
```python
n_top_features = min(
    config.max_top_features,                    # 最大特征数限制
    max(config.min_top_features, int(len(y) * 0.3))  # 样本数的30%
)
```

**可视化输出**:
- Top 15特征重要性表格
- 特征重要性柱状图对比
- 特征相关性热力图
- 类别分布饼图

### 6. 数据增强：augmentation.py

**文件作用**: 核心创新模块，通过滑动窗口和高斯噪声技术显著扩增训练数据。

**AugmentationArtifacts数据结构**:
```python
@dataclass
class AugmentationArtifacts:
    X_train: pd.DataFrame              # 原始训练集
    X_test: pd.DataFrame               # 测试集（不变）
    y_train: np.ndarray               # 原始训练标签
    y_test: np.ndarray                # 测试标签
    X_train_augmented: np.ndarray      # 增强后训练集
    y_train_augmented: np.ndarray      # 增强后训练标签
    X_train_augmented_scaled: np.ndarray  # 标准化后增强训练集
    X_test_scaled: np.ndarray          # 标准化后测试集
    scaler: StandardScaler             # 标准化器
    class_counts_original: Dict[str, int]   # 原始类别计数
    class_counts_augmented: Dict[str, int]  # 增强后类别计数
```

**滑动窗口增强算法详解**:
```python
def _sliding_window_augmentation(X, y, *, window_size, stride, noise_level):
    X_augmented = [X.values]  # 包含原始数据
    y_augmented = [y]

    n_features = X.shape[1]
    window_length = max(1, int(n_features * window_size))  # 窗口长度 = 特征数 × 70%
    step_size = max(1, int(n_features * stride))           # 步长 = 特征数 × 30%

    # 滑动窗口生成增强样本
    for start_idx in range(0, n_features - window_length + 1, step_size):
        end_idx = start_idx + window_length
        X_window = np.zeros_like(X.values)                # 创建零填充矩阵
        X_window[:, start_idx:end_idx] = X.iloc[:, start_idx:end_idx].values  # 窗口内数据
        noise = np.random.normal(0, noise_level, X_window.shape)  # 高斯噪声
        X_window += noise                                 # 添加噪声
        X_augmented.append(X_window)
        y_augmented.append(y)

    return np.vstack(X_augmented), np.hstack(y_augmented)
```

**增强策略优势**:
1. **保持数据结构**: 滑动窗口保持局部特征相关性
2. **增加多样性**: 高斯噪声增强模型鲁棒性
3. **平衡增强**: 所有类别等比例增强
4. **测试集不变**: 确保公平评估

**数据标准化**:
```python
scaler = StandardScaler()
X_train_augmented_scaled = scaler.fit_transform(X_train_augmented)  # 基于增强数据fit
X_test_scaled = scaler.transform(X_test)  # 测试集使用相同标准化
```

### 7. 建模训练：modeling.py

**文件作用**: 实现多算法并行训练、集成学习和深度神经网络，构建高性能分类器。

**ModelArtifacts数据结构**:
```python
@dataclass
class ModelArtifacts:
    results: Dict[str, Dict[str, object]]    # 所有模型结果
    trained_models: Dict[str, object]        # 训练好的模型对象
    ensemble_model: VotingClassifier         # 集成模型
    confusion_matrix_path: str               # 混淆矩阵图路径
    nn_history_path: str | None             # 神经网络训练历史路径
```

**模型定义与优化**:
```python
def define_models():
    models = {
        "Random Forest": RandomForestClassifier(
            n_estimators=30,      # 针对小数据集优化
            max_depth=3,          # 防止过拟合
            min_samples_split=8,  # 增强泛化能力
            min_samples_leaf=3,
            max_features="sqrt",
            random_state=42,
            n_jobs=-1
        ),
        "SVM": SVC(
            kernel="rbf",
            C=0.5,               # 较小的C值防止过拟合
            gamma="scale",
            probability=True,    # 支持概率预测用于集成
            random_state=42
        ),
        "XGBoost": XGBClassifier(
            n_estimators=30,
            max_depth=2,         # 浅层树防止过拟合
            learning_rate=0.05,  # 较小学习率
            subsample=0.8,       # 子采样增加随机性
            colsample_bytree=0.8,
            reg_alpha=0.5,       # L1正则化
            reg_lambda=0.5,      # L2正则化
            random_state=42
        )
    }
```

**交叉验证策略**:
```python
# 自适应交叉验证折数
augmented_counts = pd.Series(y_train_augmented).value_counts()
min_class_samples_augmented = augmented_counts.min()
cv_folds = max(2, min(5, int(min_class_samples_augmented // 3)))
cv_strategy = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)
```

**集成学习算法**:
```python
def _train_ensemble(trained_models, results, data, class_names, cv_strategy):
    # 选择Top3性能模型构建集成
    model_performance = sorted(
        ((name, info["test_accuracy"]) for name, info in results.items()),
        key=lambda x: x[1], reverse=True
    )
    top_3_models = [name for name, _ in model_performance[:3]]

    # 软投票集成
    estimators = [(name, trained_models[name]) for name in top_3_models]
    ensemble = VotingClassifier(estimators=estimators, voting="soft")
    ensemble.fit(data.X_train_augmented_scaled, data.y_train_augmented)
```

**深度神经网络架构**:
```python
def _train_neural_network():
    model = Sequential([
        Dense(512, activation="relu", input_shape=(input_dim,)),
        BatchNormalization(),
        Dropout(0.4),
        Dense(256, activation="relu"),
        BatchNormalization(),
        Dropout(0.3),
        Dense(128, activation="relu"),
        BatchNormalization(),
        Dropout(0.3),
        Dense(64, activation="relu"),
        Dropout(0.2),
        Dense(32, activation="relu"),
        Dropout(0.2),
        Dense(num_classes, activation="softmax")
    ])

    # 优化器和损失函数
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"]
    )

    # 回调函数防止过拟合
    callbacks = [
        EarlyStopping(monitor="val_loss", patience=25, restore_best_weights=True),
        ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=15, min_lr=0.0001)
    ]
```

### 8. 结果报告：reporting.py

**文件作用**: 生成详细的模型性能报告、可视化分析图表和综合评估结果。

**核心功能模块**:

1. **性能表格生成**:
```python
def build_results_dataframe(results):
    df = pd.DataFrame({
        "Model": list(results.keys()),
        "CV_Accuracy": [results[m]["cv_mean"] for m in results.keys()],
        "CV_Std": [results[m]["cv_std"] for m in results.keys()],
        "Test_Accuracy": [results[m]["test_accuracy"] for m in results.keys()],
        "Precision": [results[m]["test_precision"] for m in results.keys()],
        "Recall": [results[m]["test_recall"] for m in results.keys()],
        "F1_Score": [results[m]["test_f1"] for m in results.keys()]
    })
    return df.sort_values("F1_Score", ascending=False)  # 按F1分数排序
```

2. **详细分析可视化** (`plot_detailed_analysis`):
- 12子图综合分析面板
- 模型性能对比
- 交叉验证稳定性
- 最佳模型混淆矩阵
- ROC曲线（多类别）
- 各类别准确率分析
- 特征重要性对比

3. **综合评估报告** (`plot_comprehensive_analysis`):
- 数据增强效果展示
- 模型性能对比
- 类别准确率分析
- 训练vs测试性能对比
- 增强策略总结

4. **JSON摘要导出**:
```python
def save_summary_json():
    summary = {
        "dataset_size_original": int(len(data_bundle.df)),
        "training_size_original": int(augmentation_data.X_train.shape[0]),
        "training_size_augmented": int(augmentation_data.X_train_augmented.shape[0]),
        "augmentation_factor": float(augmentation_factor),
        "best_model": best_model,
        "best_f1_score": float(best_f1),
        "augmentation_method": "Sliding Window + Gaussian Noise"
    }
```

## 算法原理与创新点

### 1. 滑动窗口数据增强

**理论基础**: 轴承故障诊断中，特征往往存在局部相关性。滑动窗口技术能够：
- 保持局部特征间的空间关系
- 生成具有不同特征子集激活模式的样本
- 模拟实际工况中的特征变化

**数学表示**:
设原始特征向量 $\mathbf{x} \in \mathbb{R}^d$，窗口大小 $w = \lfloor d \times 0.7 \rfloor$，步长 $s = \lfloor d \times 0.3 \rfloor$

对于窗口起始位置 $i = 0, s, 2s, ...$，生成增强样本：
$$\mathbf{x}^{(i)} = \mathbf{W}_i \mathbf{x} + \boldsymbol{\epsilon}$$

其中 $\mathbf{W}_i$ 是窗口掩码矩阵，$\boldsymbol{\epsilon} \sim \mathcal{N}(0, \sigma^2 \mathbf{I})$ 为高斯噪声。

### 2. 多方法特征选择

**综合评分机制**:
$$\text{Score}(\mathbf{f}_j) = 0.3 \times S_{\text{uni}}(\mathbf{f}_j) + 0.4 \times S_{\text{RF}}(\mathbf{f}_j) + 0.3 \times S_{\text{GB}}(\mathbf{f}_j)$$

- $S_{\text{uni}}$: F-检验统计量（归一化）
- $S_{\text{RF}}$: 随机森林特征重要性（归一化）
- $S_{\text{GB}}$: 梯度提升特征重要性（归一化）

**自适应特征数量**:
$$N_{\text{features}} = \min(\text{MAX_FEATURES}, \max(\text{MIN_FEATURES}, \lfloor 0.3 \times N_{\text{samples}} \rfloor))$$

### 3. 集成学习策略

**软投票集成**: 选择性能Top3的基学习器，使用概率加权投票：
$$P(y = c | \mathbf{x}) = \frac{1}{K} \sum_{k=1}^{K} P_k(y = c | \mathbf{x})$$

其中 $K=3$ 为集成模型数量，$P_k$ 为第k个基学习器的预测概率。

### 4. 深度神经网络设计

**网络架构**: 采用渐进式维度缩减设计：
- 输入层 → 512 → 256 → 128 → 64 → 32 → 类别数
- BatchNormalization加速收敛
- Dropout防止过拟合
- 自适应学习率调整

## 数据处理方法详解

### 1. 数据预处理流程

**原始数据结构**: 94维特征数据，包含：
- **时域特征**: 均值、标准差、RMS、峰度、偏度等
- **频域特征**: 主频、谱质心、谱熵、谱带宽等
- **包络特征**: 包络RMS、包络峰度等
- **故障特征**: FTF、BPFO、BPFI、BSF相关特征

**数据清洗步骤**:
1. 元数据过滤：移除文件路径、采样率等非特征列
2. 缺失值处理：中位数填充（保持分布稳定性）
3. 异常值处理：无穷值替换为中位数
4. 标签编码：字符串故障类型转为数值编码

### 2. 数据分割策略

**分层采样**: 使用`StratifiedSplit`确保训练集和测试集中各故障类型比例一致：
```python
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y_encoded,
    test_size=0.2,           # 8:2分割
    random_state=42,         # 确保可重现
    stratify=y_encoded       # 分层采样
)
```

### 3. 数据标准化

**Z-score标准化**: 基于增强训练集计算均值和标准差：
$$\mathbf{x}_{\text{scaled}} = \frac{\mathbf{x} - \boldsymbol{\mu}_{\text{train}}}{\boldsymbol{\sigma}_{\text{train}}}$$

**关键设计**:
- 标准化参数从增强训练集学习
- 测试集使用相同参数变换
- 避免数据泄露

## 实验设计与评估

### 1. 评估指标

**多指标综合评估**:
- **Accuracy**: 整体分类准确率
- **Precision**: 精确率（宏平均）
- **Recall**: 召回率（宏平均）
- **F1-Score**: F1分数（宏平均，主要指标）

**交叉验证**: 自适应K折分层交叉验证，K值根据最小类别样本数确定。

### 2. 模型对比实验

**基线模型对比**:
- Random Forest: 集成树模型
- SVM: 支持向量机
- Logistic Regression: 逻辑回归
- XGBoost: 梯度提升（可选）
- LightGBM: 轻量级梯度提升（可选）
- Neural Network: 深度神经网络
- Ensemble: Top3模型集成

### 3. 消融实验

**数据增强效果验证**:
- 原始数据 vs 增强数据训练
- 不同增强参数对比
- 增强倍数影响分析

## 运行流程总结

### 完整管道执行流程

1. **初始化阶段**:
   - 加载配置参数
   - 设置随机种子
   - 初始化可视化环境

2. **数据准备阶段**:
   - 加载94维特征CSV文件
   - 自动推断目标列（故障类型）
   - 数据清洗和预处理
   - 标签编码

3. **特征工程阶段**:
   - 方差阈值过滤
   - 多方法特征重要性评估
   - 综合评分排序
   - 自适应特征数量选择

4. **数据增强阶段**:
   - 8:2分层数据分割
   - 滑动窗口增强算法
   - 高斯噪声注入
   - 数据标准化

5. **模型训练阶段**:
   - 基础模型并行训练
   - 交叉验证性能评估
   - 集成模型构建
   - 深度学习模型训练

6. **结果分析阶段**:
   - 性能指标计算
   - 可视化图表生成
   - 分类报告导出
   - 分析摘要保存

### 输出文件说明

**数据文件** (data/processed/问题2/):
- `model_results.csv`: 模型性能对比表
- `detailed_classification_report_augmented.csv`: 详细分类报告
- `analysis_summary_augmented.json`: 实验摘要JSON
- `top_features.csv`: 选中特征列表

**可视化文件** (figs/问题2/):
- `top_features_table.png`: Top15特征重要性表格
- `feature_analysis.png`: 特征分析综合图
- `data_augmentation_analysis.png`: 数据增强分析图
- `data_augmentation_table.png`: 增强策略摘要表
- `confusion_matrices_augmented_models.png`: 混淆矩阵对比
- `neural_network_augmented_training.png`: 神经网络训练曲线
- `model_performance_table.png`: 模型性能表格
- `detailed_analysis.png`: 12子图详细分析
- `comprehensive_augmentation_analysis.png`: 综合评估报告

## 技术特色与优势

### 1. 创新的数据增强策略
- **滑动窗口技术**: 保持局部特征相关性的同时生成多样化样本
- **自适应噪声**: 基于数据特性调整噪声水平
- **平衡增强**: 确保各类别等比例增强，避免类别不平衡

### 2. 鲁棒的特征选择
- **多方法融合**: 结合统计方法、树模型重要性多角度评估
- **自适应选择**: 根据样本数量动态调整特征数量
- **防过拟合设计**: 避免高维数据的维度诅咒

### 3. 高效的集成学习
- **性能导向**: 基于实际性能选择集成成员
- **软投票机制**: 利用预测概率而非硬分类结果
- **多样性保证**: 不同算法原理的模型组合

### 4. 全面的评估体系
- **多指标评估**: 不仅看准确率，更关注F1分数等平衡指标
- **可视化丰富**: 12+种专业图表全方位展示结果
- **实验可重现**: 固定随机种子，确保结果一致性

## 应用价值与意义

### 工程应用价值
1. **小样本学习**: 针对故障样本获取困难的实际场景优化
2. **高精度分类**: 多模型集成提升故障识别准确性
3. **实时性友好**: 特征选择减少计算复杂度
4. **扩展性强**: 模块化设计支持不同数据集和任务

### 技术创新意义
1. **数据增强创新**: 滑动窗口技术在故障诊断领域的应用
2. **特征工程优化**: 多方法综合评分的特征选择策略
3. **模型融合策略**: 性能驱动的集成学习方法
4. **评估体系完善**: 工业级的模型评估和可视化框架

这个问题2的解决方案代表了现代机器学习在故障诊断领域的最佳实践，通过创新的数据增强技术和sophisticated的建模策略，为高速列车轴承故障诊断提供了可靠的技术支撑。